{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.SparkConf\n",
       "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
       "conf: org.apache.spark.SparkConf = org.apache.spark.SparkConf@4acd67d5\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@4ceef85a\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "\n",
    "val conf = {new SparkConf().setAll(Map(\"spark.scheduler.mode\" -> \"FIFO\",\n",
    "      \"spark.speculation\" -> \"false\",\n",
    "      \"spark.reducer.maxSizeInFlight\" -> \"48m\",\n",
    "      \"spark.serializer\" -> \"org.apache.spark.serializer.KryoSerializer\",\n",
    "      \"spark.kryoserializer.buffer.max\" -> \"1g\",\n",
    "      \"spark.shuffle.file.buffer\" -> \"32k\",\n",
    "      \"spark.default.parallelism\" -> \"12\",\n",
    "      \"spark.sql.shuffle.partitions\" -> \"12\"\n",
    "    ))}\n",
    "\n",
    "    // Initialisation du SparkSession qui est le point d'entrée vers Spark SQL (donne accès aux dataframes, aux RDD,\n",
    "    // création de tables temporaires, etc., et donc aux mécanismes de distribution des calculs)\n",
    "val spark = {SparkSession\n",
    "  .builder\n",
    "  .config(conf)\n",
    "  .appName(\"TP Spark : Preprocessor\")\n",
    "  .getOrCreate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes : 108129\n",
      "Nombre de colonnes : 14\n",
      "\n",
      "\n",
      "Hello World ! from Preprocessor\n",
      "\n",
      "\n",
      "+----+\n",
      "|goal|\n",
      "+----+\n",
      "|null|\n",
      "+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 12 more fields]\n",
       "dfCasted: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df:DataFrame = spark\n",
    "      .read\n",
    "      .option(\"header\", true) \n",
    "      .option(\"inferSchema\", \"true\") // pour inférer le type de chaque colonne (Int, String, etc.)\n",
    "      .csv(\"/home/jorge/Documents/Cours/Spark/RepoAdotTPs/data/train_clean.csv\")\n",
    "\n",
    "println(s\"Nombre de lignes : ${df.count}\")\n",
    "println(s\"Nombre de colonnes : ${df.columns.length}\")\n",
    "println(\"\\n\")\n",
    "println(\"Hello World ! from Preprocessor\")\n",
    "println(\"\\n\")\n",
    "\n",
    "// val dfcasted:DataFrame = df\n",
    "//     .withColumn(\"goal\",$\"goal\".cast(\"Int\"))\n",
    "//     .withColumn(\"deadline\",$\"deadline\".cast(\"Int\"))\n",
    "//     .withColumn(\"state_changed_at\",$\"state_changed_at\".cast(\"Int\"))\n",
    "//     .withColumn(\"created_at\",$\"created_at\".cast(\"Int\"))\n",
    "//     .withColumn(\"launched_at\", $\"launched_at\".cast(\"Int\"))\n",
    "//     .withColumn(\"backers_count\", $\"backers_count\".cast(\"Int\"))\n",
    "//     .withColumn(\"final_status\", $\"final_status\".cast(\"Int\"))\n",
    "\n",
    "val dfCasted: DataFrame = df\n",
    "    .withColumn(\"goal\", $\"goal\".cast(\"Int\"))\n",
    "    .withColumn(\"deadline\" , $\"deadline\".cast(\"Int\"))\n",
    "    .withColumn(\"state_changed_at\", $\"state_changed_at\".cast(\"Int\"))\n",
    "    .withColumn(\"created_at\", $\"created_at\".cast(\"Int\"))\n",
    "    .withColumn(\"launched_at\", $\"launched_at\".cast(\"Int\"))\n",
    "    .withColumn(\"backers_count\", $\"backers_count\".cast(\"Int\"))\n",
    "    .withColumn(\"final_status\", $\"final_status\".cast(\"Int\"))\n",
    "    .dropDuplicates(\"deadline\")\n",
    "    .filter(!isnull($\"state_changed_at\"))\n",
    "    .withColumn(\"country\",when($\"country\" === \"False\",$\"currency\").otherwise($\"country\"))\n",
    "    .filter(($\"disable_communication\"===\"True\") || ($\"disable_communication\"===\"False\"))\n",
    "    .drop(\"disable_communication\")\n",
    "    .filter($\"country\" rlike \".{2}\")\n",
    "    .filter($\"currency\" rlike \".{3}\")\n",
    "    .drop(\"backers_count\",\"state_changed_at\")\n",
    "    .withColumn(\"days_campaign\",datediff(from_unixtime($\"deadline\"),from_unixtime($\"launched_at\")))\n",
    "    .withColumn(\"hours_prepa\",(($\"launched_at\"-$\"created_at\")/60).cast(\"Int\"))\n",
    "    .drop(\"launched_at\",\"deadline\",\"created_at\")\n",
    "    .withColumn(\"name\",lower($\"name\"))\n",
    "    .withColumn(\"desc\",lower($\"desc\"))\n",
    "    .withColumn(\"keywords\",lower($\"keywords\"))\n",
    "    .withColumn(\"text\",concat($\"name\",lit(\" \"),$\"desc\",lit(\" \"),$\"keywords\"))\n",
    "    .withColumn(\"days_campaign\",when(isnull($\"days_campaign\"),-1).otherwise($\"days_campaign\"))\n",
    "    .withColumn(\"hours_prepa\",when(isnull($\"hours_prepa\"),-1).otherwise($\"hours_prepa\"))\n",
    "    .withColumn(\"goal\",when(isnull($\"goal\"),-1).otherwise($\"goal\"))\n",
    "    .withColumn(\"country\",when(isnull($\"country\"),\" \").otherwise($\"country\"))\n",
    "    .withColumn(\"currency\",when(isnull($\"currency\"),\" \").otherwise($\"currency\"))\n",
    "\n",
    "\n",
    "// df3.write.parquet(\"/home/jorge/Documents/Git/spark_project_kickstarter_2019_2020/cleanData.parquet\")\n",
    "df.select($\"goal\").filter(col(\"goal\").isNull).show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "30: error: not found: value dfClean",
     "output_type": "error",
     "traceback": [
      "<console>:30: error: not found: value dfClean",
      "       dfClean",
      "       ^",
      ""
     ]
    }
   ],
   "source": [
    "dfCasted\n",
    "  .select(\"goal\", \"backers_count\", \"final_status\")\n",
    "  .describe()\n",
    "  .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val n = 5\n",
    "\n",
    "dfCasted\n",
    "    .select(\"name\",\"goal\", \"backers_count\", \"final_status\")\n",
    "    .show(n)\n",
    "\n",
    "dfCasted\n",
    "    .select(\"country\",\"keywords\",\"disable_communication\",\"currency\")\n",
    "    .show(n)\n",
    "\n",
    "dfCasted\n",
    "    .select(\"deadline\",\"state_changed_at\",\"created_at\",\"launched_at\")\n",
    "    .show(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// dfCasted.groupBy(\"disable_communication\").count.orderBy($\"count\".desc).show(100)\n",
    "// dfCasted.groupBy(\"disable_communication\").count.orderBy($\"count\".desc).show\n",
    "// dfCasted.groupBy(\"country\").count.orderBy($\"count\".desc).show(100)\n",
    "// dfClean.groupBy(\"currency\").count.orderBy($\"count\".desc).show(100)\n",
    "// dfCasted.select(\"deadline\").dropDuplicates.show()\n",
    "\n",
    "// (dfCasted.select(\"deadline\").dropDuplicates.count()\n",
    "//  ,dfCasted.select(\"deadline\").count())\n",
    "\n",
    "// dfCasted.groupBy(\"state_changed_at\").count.orderBy($\"count\".desc).show(100)\n",
    "// dfCasted.groupBy(\"backers_count\").count.orderBy($\"count\".desc).show(100)\n",
    "// dfCasted.select(\"goal\", \"final_status\").show(30)\n",
    "// dfCasted.groupBy(\"country\", \"currency\").count.orderBy($\"count\".desc).show(50)\n",
    "\n",
    "// Cleaning à faire: \n",
    "// Only keep rows with \"True\" or \"False\" in disable_communication\n",
    "// drop disable_communication\n",
    "// drop rows where regex or different from the main countries (after\n",
    "// trying to fill with currency stage later)\n",
    "\n",
    "// same than above with the country culumn\n",
    "// dropduplicates in id column --done\n",
    "// filter rows where state_changed_at null\n",
    "// infer country from / currency if country is null (befre dropping countries)\n",
    "// US -> US , GB ->GB, CA->CA, AU-AU, NL->NL\n",
    "// "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfClean:DataFrame = dfCasted\n",
    "    .dropDuplicates(\"deadline\")\n",
    "    .filter(!isnull($\"state_changed_at\"))\n",
    "    .withColumn(\"country\",when($\"country\" === \"False\",$\"currency\").otherwise($\"country\"))\n",
    "    .filter(($\"disable_communication\"===\"True\") || ($\"disable_communication\"===\"False\"))\n",
    "    .drop(\"disable_communication\")\n",
    "    .filter($\"country\" rlike \".{2}\")\n",
    "    .filter($\"currency\" rlike \".{3}\")\n",
    "    .drop(\"backers_count\",\"state_changed_at\")\n",
    "\n",
    "dfClean\n",
    "    .select(\"name\",\"goal\",\"final_status\")\n",
    "    .show(n)\n",
    "\n",
    "dfClean\n",
    "    .select(\"country\",\"keywords\",\"currency\")\n",
    "    .show(n)\n",
    "\n",
    "dfClean\n",
    "    .select(\"deadline\",\"created_at\",\"launched_at\")\n",
    "    .show(n)\n",
    "\n",
    "// df.filter($\"country\" === \"False\")\n",
    "//   .groupBy(\"currency\")\n",
    "//   .count\n",
    "//   .orderBy($\"count\".desc)\n",
    "//   .show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Important:  col equivalent to $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Solution proposée\n",
    "\n",
    "// def cleanCountry(country: String, currency: String): String = {\n",
    "//   if (country == \"False\")\n",
    "//     currency\n",
    "//   else\n",
    "//     country\n",
    "// }\n",
    "\n",
    "// def cleanCurrency(currency: String): String = {\n",
    "//   if (currency != null && currency.length != 3)\n",
    "//     null\n",
    "//   else\n",
    "//     currency\n",
    "// }\n",
    "\n",
    "// val cleanCountryUdf = udf(cleanCountry _)\n",
    "// val cleanCurrencyUdf = udf(cleanCurrency _)\n",
    "\n",
    "// val dfCountry: DataFrame = dfNoFutur\n",
    "//   .withColumn(\"country2\", cleanCountryUdf($\"country\", $\"currency\"))\n",
    "//   .withColumn(\"currency2\", cleanCurrencyUdf($\"currency\"))\n",
    "//   .drop(\"country\", \"currency\")\n",
    "\n",
    "// // ou encore, en utilisant sql.functions.when:\n",
    "// dfNoFutur\n",
    "//   .withColumn(\"country2\", when($\"country\" === \"False\", $\"currency\").otherwise($\"country\"))\n",
    "//   .withColumn(\"currency2\", when($\"country\".isNotNull && length($\"currency\") =!= 3, null).otherwise($\"currency\"))\n",
    "//   .drop(\"country\", \"currency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val df2:DataFrame = dfClean\n",
    "    .withColumn(\"days_campaign\",datediff(from_unixtime($\"deadline\"),from_unixtime($\"launched_at\")))\n",
    "    .withColumn(\"hours_prepa\",(($\"launched_at\"-$\"created_at\")/60).cast(\"Int\"))\n",
    "    .drop(\"launched_at\",\"deadline\",\"created_at\")\n",
    "    .withColumn(\"name\",lower($\"name\"))\n",
    "    .withColumn(\"desc\",lower($\"desc\"))\n",
    "    .withColumn(\"keywords\",lower($\"keywords\"))\n",
    "    \n",
    "\n",
    "val df3:DataFrame = df2\n",
    "    .withColumn(\"text\",concat($\"name\",lit(\" \"),$\"desc\",lit(\" \"),$\"keywords\"))\n",
    "    .withColumn(\"days_campaign\",when(isnull($\"days_campaign\"),-1).otherwise($\"days_campaign\"))\n",
    "    .withColumn(\"hours_prepa\",when(isnull($\"hours_prepa\"),-1).otherwise($\"hours_prepa\"))\n",
    "    .withColumn(\"goal\",when(isnull($\"goal\"),-1).otherwise($\"goal\"))\n",
    "    .withColumn(\"country\",when(isnull($\"country\"),\" \").otherwise($\"country\"))\n",
    "    .withColumn(\"currency\",when(isnull($\"currency\"),\" \").otherwise($\"currency\"))\n",
    "\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3\n",
    "    .select(\"name\",\"goal\",\"final_status\")\n",
    "    .show(n)\n",
    "\n",
    "df3\n",
    "    .select(\"country\",\"keywords\",\"currency\")\n",
    "    .show(n)\n",
    "\n",
    "\n",
    "df3\n",
    "    .select(\"days_campaign\",\"hours_prepa\",\"text\")\n",
    "    .show(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.write.parquet(\"/home/jorge/Documents/Git/spark_project_kickstarter_2019_2020/cleanData.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// df.select(\"country\").map(line => (line.toString(),line.toString.length())).orderBy($\"_2\".desc).show(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
