{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.88:4040\n",
       "SparkContext available as 'sc' (version = 2.4.4, master = local[*], app id = local-1572432463337)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world ! from Trainer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.SparkConf\n",
       "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.SparkConf\n",
       "import org.apache.spark.ml.feature.{RegexTokenizer, StopWordsRemover, StringIndexer, CountVectorizer, CountVectorizerModel, VectorAssembler, IDF, OneHotEncoderEstimator}\n",
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "conf: org.apache.spark.SparkConf = org.apache.spark.SparkConf@2579fcc2\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@5f38b140\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.ml.feature.{RegexTokenizer,StopWordsRemover,\n",
    "                                    StringIndexer,CountVectorizer,\n",
    "                                    CountVectorizerModel,VectorAssembler,\n",
    "                                   IDF,OneHotEncoderEstimator}\n",
    "\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
    "\n",
    "// import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "// import org.apache.spark.ml.evaluation\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "val conf = new SparkConf().setAll(Map(\n",
    "      \"spark.scheduler.mode\" -> \"FIFO\",\n",
    "      \"spark.speculation\" -> \"false\",\n",
    "      \"spark.reducer.maxSizeInFlight\" -> \"48m\",\n",
    "      \"spark.serializer\" -> \"org.apache.spark.serializer.KryoSerializer\",\n",
    "      \"spark.kryoserializer.buffer.max\" -> \"1g\",\n",
    "      \"spark.shuffle.file.buffer\" -> \"32k\",\n",
    "      \"spark.default.parallelism\" -> \"12\",\n",
    "      \"spark.sql.shuffle.partitions\" -> \"12\",\n",
    "      \"spark.driver.maxResultSize\" -> \"2g\"\n",
    "    ))\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder\n",
    "  .config(conf)\n",
    "  .appName(\"TP Spark : Trainer\")\n",
    "  .getOrCreate()\n",
    "\n",
    "\n",
    "/*******************************************************************************\n",
    "  *\n",
    "  *       TP 3\n",
    "  *\n",
    "  *       - lire le fichier sauvegarder précédemment\n",
    "  *       - construire les Stages du pipeline, puis les assembler\n",
    "  *       - trouver les meilleurs hyperparamètres pour l'entraînement du pipeline avec une grid-search\n",
    "  *       - Sauvegarder le pipeline entraîné\n",
    "  *\n",
    "  *       if problems with unimported modules => sbt plugins update\n",
    "  *\n",
    "  ********************************************************************************/\n",
    "\n",
    "println(\"hello world ! from Trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df:DataFrame = spark.read.parquet(\"/home/jorge/Documents/Cours/Spark/RepoAdotTPs/data/prepared_trainingset/\")\n",
    "\n",
    "// df.select(\"project_id\", \"name\", \"desc\", \"goal\").show(5)\n",
    "// df.select(\"keywords\", \"final_status\", \"country2\", \"currency2\").show(5)\n",
    "// df.select(\"deadline2\", \"created_at2\", \"launched_at2\", \"days_campaign\").show(5)\n",
    "// df.select(\"hours_prepa\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer: org.apache.spark.ml.feature.RegexTokenizer = regexTok_90f95d9fbda1\n",
       "remover: org.apache.spark.ml.feature.StopWordsRemover = stopWords_6642ff7f2608\n",
       "cvModel: org.apache.spark.ml.feature.CountVectorizer = cntVec_3d7b967aea14\n",
       "idf: org.apache.spark.ml.feature.IDF = idf_e6e6e41434da\n",
       "indexerCountry: org.apache.spark.ml.feature.StringIndexer = strIdx_14b00bde8a30\n",
       "indexerCurrency: org.apache.spark.ml.feature.StringIndexer = strIdx_ef7429f34d0d\n",
       "encoder: org.apache.spark.ml.feature.OneHotEncoderEstimator = oneHotEncoder_5f7bb18aabc5\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_97c613ba91fd\n",
       "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_8beeec840755\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tokenizer = new RegexTokenizer()\n",
    "  .setPattern(\"\\\\W+\")\n",
    "  .setGaps(true)\n",
    "  .setInputCol(\"text\")\n",
    "  .setOutputCol(\"tokens\")\n",
    "// val dfTokenized = tokenizer.transform(df)\n",
    "\n",
    "\n",
    "val remover = new StopWordsRemover()\n",
    "  .setInputCol(tokenizer.getOutputCol)\n",
    "  .setOutputCol(\"filtered\")\n",
    "\n",
    "// val dfsw = remover.transform(dfTokenized)\n",
    " \n",
    "\n",
    "val cvModel: CountVectorizer = new CountVectorizer()\n",
    "    .setInputCol(remover.getOutputCol)\n",
    "    .setOutputCol(\"vect\")\n",
    "    \n",
    "    \n",
    "\n",
    "// val dfv = cvModel.fit(dfsw).transform(dfsw)\n",
    "\n",
    "\n",
    "\n",
    "val idf = new IDF()\n",
    "    .setInputCol(cvModel.getOutputCol)\n",
    "    .setOutputCol(\"tfidf\")\n",
    "\n",
    "// val idfModel = idf.fit(dfv)\n",
    "\n",
    "// val rescaledData = idfModel.transform(dfv)\n",
    "                                      \n",
    "\n",
    "val indexerCountry = new StringIndexer()\n",
    "  .setInputCol(\"country2\")\n",
    "  .setOutputCol(\"country_indexed\")\n",
    "\n",
    "val indexerCurrency = new StringIndexer()\n",
    "  .setInputCol(\"currency2\")\n",
    "  .setOutputCol(\"currency_indexed\")\n",
    "\n",
    "\n",
    "// val indexedCountry = indexerCountry.fit(rescaledData).transform(rescaledData)\n",
    "// val indexedCountryCurrency = indexerCurrency.fit(indexedCountry).transform(indexedCountry)\n",
    "\n",
    "\n",
    "val encoder = new OneHotEncoderEstimator()\n",
    "  .setInputCols(Array(\"country_indexed\", \"currency_indexed\"))\n",
    "  .setOutputCols(Array(\"country_onehot\", \"currency_onehot\"))\n",
    "\n",
    "// val model = encoder.fit(indexedCountryCurrency)\n",
    "// val encoded = model.transform(indexedCountryCurrency)\n",
    "\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(Array(\"tfidf\",\"days_campaign\",\"hours_prepa\",\"goal\",\"country_onehot\",\"currency_onehot\"))\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "val lr = new LogisticRegression()\n",
    "  .setElasticNetParam(0.0)\n",
    "  .setFitIntercept(true)\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setLabelCol(\"final_status\")\n",
    "  .setStandardization(true)\n",
    "  .setPredictionCol(\"predictions\")\n",
    "  .setRawPredictionCol(\"raw_predictions\")\n",
    "  .setThresholds(Array(0.7, 0.3))\n",
    "  .setTol(1.0e-6)\n",
    "  .setMaxIter(20)\n",
    "\n",
    "// val transformed = assembler\n",
    "//     .setHandleInvalid(\"skip\")\n",
    "//     .transform(encoded)\n",
    "//     .drop(\"project_id\",\"name\",\"desc\",\"goal\",\"keywords\",\n",
    "//          \"country2\",\"currency2\",\"deadline2\",\"created_at2\",\"launched_at2\",\n",
    "//          \"days_campaign\",\"hours_prepa\",\"text\",\"tokens\",\"filtered\",\"vect\",\n",
    "//          \"country_indexed\",\"currency_indexed\",\"tfidf\",\"days_campaign\",\n",
    "//           \"hours_prepa\",\"goal\",\"country_onehot\",\"currency_onehot\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_a3e0987b9dba\n",
       "model: org.apache.spark.ml.PipelineModel = pipeline_a3e0987b9dba\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// transformed.show(numRows=5,truncate=false)\n",
    "\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, remover,cvModel,idf,indexerCountry,\n",
    "                  indexerCurrency,encoder, assembler,lr ))\n",
    "\n",
    "// Fit the pipeline to training documents.\n",
    "val model = pipeline.fit(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------+\n",
      "|                text|predictions|final_status|\n",
      "+--------------------+-----------+------------+\n",
      "|american options ...|        1.0|           0|\n",
      "|iheadbones bone c...|        0.0|           0|\n",
      "|the fridge magazi...|        0.0|           0|\n",
      "|support new men's...|        0.0|           0|\n",
      "|can('t) a psychol...|        0.0|           0|\n",
      "|fragmented fate e...|        0.0|           0|\n",
      "|transport (suspen...|        0.0|           0|\n",
      "|the secret life o...|        0.0|           0|\n",
      "|cc survival decep...|        0.0|           0|\n",
      "|the best protein ...|        0.0|           0|\n",
      "|paradise falls pa...|        1.0|           0|\n",
      "|the chalet woodsh...|        1.0|           1|\n",
      "|vagabond mobile g...|        0.0|           0|\n",
      "|southern shakespe...|        1.0|           1|\n",
      "|leviathan: montau...|        1.0|           1|\n",
      "|the candle tray h...|        0.0|           0|\n",
      "|sun skin the miss...|        0.0|           0|\n",
      "|7sonic debut stud...|        0.0|           0|\n",
      "|the hades pit: a ...|        0.0|           0|\n",
      "|the fitness refin...|        0.0|           0|\n",
      "|the stone garden ...|        0.0|           0|\n",
      "|\"make da chedda m...|        0.0|           0|\n",
      "|highflight magazi...|        0.0|           0|\n",
      "|flour child creat...|        0.0|           0|\n",
      "|coming to you liv...|        0.0|           0|\n",
      "|the tiny tyrant's...|        0.0|           0|\n",
      "|tdi bassline the ...|        0.0|           0|\n",
      "|adventures of boo...|        0.0|           0|\n",
      "|rebeccas piano ta...|        0.0|           0|\n",
      "|patent art poster...|        1.0|           1|\n",
      "|a pigeon of bosto...|        1.0|           1|\n",
      "|'time at the bar!...|        0.0|           0|\n",
      "|bees and honey, h...|        0.0|           0|\n",
      "|quickscan discoun...|        0.0|           0|\n",
      "|help fund mags' j...|        0.0|           0|\n",
      "|self-publish my n...|        0.0|           0|\n",
      "|2015 mwg antholog...|        0.0|           0|\n",
      "|112cam. film a cr...|        0.0|           0|\n",
      "|black swamp - nat...|        1.0|           1|\n",
      "|help a lousir mak...|        0.0|           0|\n",
      "|craft-oriented co...|        0.0|           0|\n",
      "|\"support trez's d...|        0.0|           0|\n",
      "|spiritwalker born...|        0.0|           0|\n",
      "|farmer dreams [a ...|        0.0|           0|\n",
      "|music review webs...|        0.0|           0|\n",
      "|a walk through th...|        0.0|           0|\n",
      "|publishing a hist...|        0.0|           0|\n",
      "|john and clive th...|        0.0|           0|\n",
      "|holiday collectio...|        0.0|           0|\n",
      "|robotics competit...|        0.0|           0|\n",
      "|anise fine arts &...|        0.0|           0|\n",
      "|\"cut dui death wi...|        0.0|           0|\n",
      "|ithaca diaries, c...|        1.0|           1|\n",
      "|save the agawam c...|        1.0|           1|\n",
      "|ultimus qi: wirel...|        0.0|           0|\n",
      "|parts alley parts...|        0.0|           0|\n",
      "|lunicycle: the un...|        1.0|           1|\n",
      "|mural printing,di...|        0.0|           0|\n",
      "|the happy chef th...|        0.0|           0|\n",
      "|e marie fall15 ny...|        0.0|           0|\n",
      "|superstition moun...|        0.0|           0|\n",
      "|a function of rat...|        1.0|           1|\n",
      "|life interrupted ...|        0.0|           0|\n",
      "|relentless love e...|        1.0|           1|\n",
      "|'signing in' - ep...|        0.0|           0|\n",
      "|tomato juice toma...|        0.0|           0|\n",
      "|studio dance art ...|        0.0|           0|\n",
      "|the zen commuter ...|        0.0|           0|\n",
      "|thea: the awakeni...|        0.0|           0|\n",
      "|redneck candles &...|        0.0|           0|\n",
      "|2nd amendment wat...|        0.0|           0|\n",
      "|haunters - the mo...|        1.0|           1|\n",
      "|personally predic...|        0.0|           0|\n",
      "|amoeblobs an addi...|        0.0|           0|\n",
      "|crimefighting toa...|        0.0|           0|\n",
      "|kendama video tut...|        1.0|           1|\n",
      "|diy kit: 2015 cal...|        1.0|           1|\n",
      "|go-anywhere blank...|        1.0|           1|\n",
      "|the wheatones rec...|        1.0|           1|\n",
      "|o human star volu...|        1.0|           1|\n",
      "|fopydo smartstand...|        0.0|           0|\n",
      "|mamma's boy - the...|        0.0|           0|\n",
      "|bigphone videopho...|        0.0|           0|\n",
      "|\"polish \"\"\"\"\"\"\"\"\"...|        0.0|           0|\n",
      "|catfish catcher c...|        0.0|           0|\n",
      "|new york business...|        0.0|           0|\n",
      "|rankmatch - intel...|        0.0|           0|\n",
      "|godfall: empire o...|        0.0|           0|\n",
      "|so you want to wo...|        1.0|           0|\n",
      "|\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...|        0.0|           0|\n",
      "|construction pape...|        1.0|           0|\n",
      "|'72 sols' a 3d ja...|        0.0|           0|\n",
      "|cryptos in print ...|        1.0|           1|\n",
      "|chasing ireland #...|        0.0|           0|\n",
      "|b-rabbit tv comed...|        1.0|           1|\n",
      "|our town's first ...|        0.0|           0|\n",
      "|the organ broker ...|        1.0|           1|\n",
      "|masala organic ac...|        0.0|           0|\n",
      "|the giving garden...|        1.0|           0|\n",
      "|plasma frequency ...|        0.0|           0|\n",
      "+--------------------+-----------+------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(df).columns\n",
    "\n",
    "model.transform(df).select(\"text\",\"predictions\",\"final_status\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [project_id: string, name: string ... 12 more fields]\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [project_id: string, name: string ... 12 more fields]\n",
       "size: (Long, Long) = (96845,10769)\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train,test) = df.randomSplit(Array[Double](0.9, 0.1))\n",
    "val size = (train.count,test.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model2: org.apache.spark.ml.PipelineModel = pipeline_a3e0987b9dba\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model2 = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------------+\n",
      "|final_status|predictions|         probability|\n",
      "+------------+-----------+--------------------+\n",
      "|           0|        0.0|[0.99999987707389...|\n",
      "|           1|        0.0|[0.99999999992283...|\n",
      "|           0|        1.0|[0.01376248593450...|\n",
      "|           0|        0.0|[0.99977858802339...|\n",
      "|           0|        0.0|[0.99999968129451...|\n",
      "|           1|        1.0|[0.09710237657632...|\n",
      "|           0|        0.0|[1.0,2.0860542810...|\n",
      "|           0|        0.0|[0.99999999997036...|\n",
      "|           0|        0.0|[0.95399092757000...|\n",
      "|           0|        0.0|[1.0,1.5001636745...|\n",
      "|           1|        0.0|[0.79988997181747...|\n",
      "|           0|        0.0|[0.99888812244579...|\n",
      "|           0|        0.0|[0.99999970884972...|\n",
      "|           1|        1.0|[8.26967814844707...|\n",
      "|           0|        0.0|[0.76357898886251...|\n",
      "|           0|        0.0|[0.99999999991236...|\n",
      "|           0|        1.0|[0.17061237784837...|\n",
      "|           1|        1.0|[0.24769895038902...|\n",
      "|           0|        0.0|[0.99999998597312...|\n",
      "|           0|        0.0|[1.0,2.0975089879...|\n",
      "|           0|        1.0|[0.01195308869443...|\n",
      "|           0|        1.0|[0.00189962759542...|\n",
      "|           0|        0.0|[0.99999999991798...|\n",
      "|           0|        0.0|[0.99999999999999...|\n",
      "|           0|        0.0|[0.99495601239037...|\n",
      "|           0|        0.0|[0.99999999999997...|\n",
      "|           0|        1.0|[0.21881447177227...|\n",
      "|           0|        0.0|[0.97677269150881...|\n",
      "|           0|        0.0|[0.85202564207889...|\n",
      "|           0|        0.0|[0.99999986991747...|\n",
      "|           1|        1.0|[0.40988409602288...|\n",
      "|           0|        1.0|[0.00582532123554...|\n",
      "|           1|        0.0|[0.99999999999997...|\n",
      "|           1|        0.0|[0.74774998945069...|\n",
      "|           0|        0.0|[0.99976194078855...|\n",
      "|           1|        0.0|[0.90985433859861...|\n",
      "|           0|        0.0|[0.99997445937478...|\n",
      "|           0|        0.0|[0.99999986398530...|\n",
      "|           0|        0.0|[0.99966722105611...|\n",
      "|           1|        0.0|[0.98816667048525...|\n",
      "|           0|        0.0|[0.99292084189321...|\n",
      "|           0|        1.0|[0.00250027688355...|\n",
      "|           0|        1.0|[0.45665769572062...|\n",
      "|           1|        1.0|[0.04123096092536...|\n",
      "|           0|        0.0|[0.99994317625433...|\n",
      "|           0|        1.0|[0.67927856434320...|\n",
      "|           0|        0.0|[0.99737013255535...|\n",
      "|           0|        0.0|[0.99964290846821...|\n",
      "|           0|        0.0|[0.99999999999987...|\n",
      "|           0|        0.0|[0.88715576620909...|\n",
      "|           1|        1.0|[0.69729054900107...|\n",
      "|           0|        1.0|[0.68443266086994...|\n",
      "|           0|        1.0|[0.00357070827644...|\n",
      "|           0|        0.0|[0.99999836391288...|\n",
      "|           0|        1.0|[0.01088758405377...|\n",
      "|           0|        1.0|[1.61595383681357...|\n",
      "|           0|        0.0|[0.84056825973695...|\n",
      "|           1|        0.0|[0.86542789682689...|\n",
      "|           0|        0.0|[0.99994372987332...|\n",
      "|           0|        0.0|[0.99999999827210...|\n",
      "|           0|        0.0|[0.99999199537587...|\n",
      "|           1|        1.0|[2.43280538360189...|\n",
      "|           0|        0.0|[0.99999999179190...|\n",
      "|           0|        0.0|[0.97461332862592...|\n",
      "|           0|        0.0|[0.93495824671736...|\n",
      "|           0|        0.0|[0.99999999984062...|\n",
      "|           1|        0.0|[0.99999999999520...|\n",
      "|           0|        0.0|[0.99999999635808...|\n",
      "|           0|        0.0|[0.99998549492121...|\n",
      "|           1|        1.0|[0.06152744056304...|\n",
      "|           0|        0.0|[0.97857569405311...|\n",
      "|           0|        0.0|[0.99887758171899...|\n",
      "|           0|        0.0|[0.99999999999963...|\n",
      "|           0|        0.0|[0.88776690027506...|\n",
      "|           0|        0.0|[0.99983387008788...|\n",
      "|           0|        1.0|[0.08038843012818...|\n",
      "|           0|        1.0|[0.00193766157138...|\n",
      "|           0|        0.0|[0.99999841262416...|\n",
      "|           0|        1.0|[0.04716554622777...|\n",
      "|           0|        0.0|[0.99999959215368...|\n",
      "|           0|        0.0|[0.99999999999990...|\n",
      "|           0|        1.0|[3.64454776221913...|\n",
      "|           0|        0.0|[0.99999999762403...|\n",
      "|           1|        0.0|[0.99999999993269...|\n",
      "|           0|        0.0|[0.99998237623292...|\n",
      "|           0|        0.0|[1.0,1.1064452819...|\n",
      "|           0|        0.0|[0.99864495050674...|\n",
      "|           1|        1.0|[9.38007625943880...|\n",
      "|           0|        0.0|[0.99231041468686...|\n",
      "|           0|        0.0|[0.99383673983914...|\n",
      "|           0|        0.0|[0.99996189112586...|\n",
      "|           0|        0.0|[1.0,2.7586288187...|\n",
      "|           0|        0.0|[0.95853396447741...|\n",
      "|           1|        1.0|[0.09606052454707...|\n",
      "|           1|        1.0|[0.63836925650137...|\n",
      "|           1|        0.0|[0.99999869244039...|\n",
      "|           0|        0.0|[0.99999999999999...|\n",
      "|           0|        0.0|[0.99998709928729...|\n",
      "|           0|        0.0|[0.99999185744770...|\n",
      "|           0|        1.0|[3.79602975907447...|\n",
      "+------------+-----------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictions: org.apache.spark.sql.DataFrame = [project_id: string, name: string ... 24 more fields]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = model2.transform(test)\n",
    "\n",
    "predictions.select(\"final_status\",\"predictions\",\"probability\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "53: error: not found: value LabeledPoint",
     "output_type": "error",
     "traceback": [
      "<console>:53: error: not found: value LabeledPoint",
      "       val predictionAndLabels = test.map { case LabeledPoint(label, features) =>",
      "                                                 ^",
      "<console>:54: error: value predict is not a member of org.apache.spark.ml.PipelineModel",
      "         val prediction = model2.predict(features)",
      "                                 ^",
      "<console>:50: error: value clearThreshold is not a member of org.apache.spark.ml.PipelineModel",
      "       model2.clearThreshold",
      "              ^",
      ""
     ]
    }
   ],
   "source": [
    "// // Clear the prediction threshold so the model will return probabilities\n",
    "// model2.clearThreshold\n",
    "\n",
    "// // Compute raw scores on the test set\n",
    "// val predictionAndLabels = test.map { case LabeledPoint(label, features) =>\n",
    "//   val prediction = model2.predict(features)\n",
    "//   (prediction, label)\n",
    "// }\n",
    "\n",
    "// // Instantiate metrics object\n",
    "// val metrics = new BinaryClassificationMetrics(predictionAndLabels)\n",
    "\n",
    "// // Precision by threshold\n",
    "// val precision = metrics.precisionByThreshold\n",
    "// precision.foreach { case (t, p) =>\n",
    "//   println(s\"Threshold: $t, Precision: $p\")\n",
    "// }\n",
    "\n",
    "// // Recall by threshold\n",
    "// val recall = metrics.recallByThreshold\n",
    "// recall.foreach { case (t, r) =>\n",
    "//   println(s\"Threshold: $t, Recall: $r\")\n",
    "// }\n",
    "\n",
    "// // Precision-Recall Curve\n",
    "// val PRC = metrics.pr\n",
    "\n",
    "// // F-measure\n",
    "// val f1Score = metrics.fMeasureByThreshold\n",
    "// f1Score.foreach { case (t, f) =>\n",
    "//   println(s\"Threshold: $t, F-score: $f, Beta = 1\")\n",
    "// }\n",
    "\n",
    "// val beta = 0.5\n",
    "// val fScore = metrics.fMeasureByThreshold(beta)\n",
    "// f1Score.foreach { case (t, f) =>\n",
    "//   println(s\"Threshold: $t, F-score: $f, Beta = 0.5\")\n",
    "// }\n",
    "\n",
    "// // AUPRC\n",
    "// val auPRC = metrics.areaUnderPR\n",
    "// println(s\"Area under precision-recall curve = $auPRC\")\n",
    "\n",
    "// // Compute thresholds used in ROC and PR curves\n",
    "// val thresholds = precision.map(_._1)\n",
    "\n",
    "// // ROC Curve\n",
    "// val roc = metrics.roc\n",
    "\n",
    "// // AUROC\n",
    "// val auROC = metrics.areaUnderROC\n",
    "// println(s\"Area under ROC = $auROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.624888227666162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_6bedc65f5757\n",
       "f1: Double = 0.624888227666162\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    "      .setLabelCol(\"final_status\")\n",
    "      .setPredictionCol(\"predictions\")\n",
    "      .setMetricName(\"f1\")\n",
    "val f1 = evaluator.evaluate(predictions)\n",
    "println(\"Test set accuracy = \" + f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder, CrossValidatorModel}\n",
       "import org.apache.spark.ml.param.ParamMap\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder,CrossValidatorModel,TrainValidationSplit}\n",
    "import org.apache.spark.ml.param.ParamMap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grid: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\tlogreg_8beeec840755-regParam: 1.0E-7\n",
       "}, {\n",
       "\tlogreg_8beeec840755-regParam: 1.0E-5\n",
       "}, {\n",
       "\tlogreg_8beeec840755-regParam: 0.001\n",
       "}, {\n",
       "\tlogreg_8beeec840755-regParam: 0.1\n",
       "})\n",
       "trainValidationSplit: org.apache.spark.ml.tuning.TrainValidationSplit = tvs_dc9f31a4ea30\n",
       "model: org.apache.spark.ml.tuning.TrainValidationSplitModel = tvs_dc9f31a4ea30\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val grid = new ParamGridBuilder()\n",
    "    .addGrid(lr.regParam,Array(10e-8,10e-6,10e-4,10e-2))\n",
    "    .build()\n",
    "\n",
    "// val cv = new CrossValidator()\n",
    "//   .setEstimator(pipeline)\n",
    "//   .setEvaluator(evaluator)\n",
    "//   .setEstimatorParamMaps(grid)\n",
    "//   .setNumFolds(5)\n",
    "\n",
    "// val cvModel = cv.fit(df)\n",
    "\n",
    "val trainValidationSplit = new TrainValidationSplit()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(evaluator)\n",
    "  .setEstimatorParamMaps(grid)\n",
    "  // 80% of the data will be used for training and the remaining 20% for validation.\n",
    "  .setTrainRatio(0.7)\n",
    "\n",
    "val model = trainValidationSplit.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------+--------------------+\n",
      "|                name|final_status|predictions|         probability|\n",
      "+--------------------+------------+-----------+--------------------+\n",
      "|             the uvu|           0|        0.0|[0.89219364023528...|\n",
      "|have mic will tra...|           1|        0.0|[0.85525926772793...|\n",
      "|owlboard fpga dev...|           0|        1.0|[0.40587133154625...|\n",
      "|            darkarts|           0|        0.0|[0.85331445021782...|\n",
      "|\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...|           0|        0.0|[0.83254182259887...|\n",
      "|please join me in...|           1|        1.0|[0.60509109830901...|\n",
      "|magnifying glass ...|           0|        0.0|[0.99496553490080...|\n",
      "| teacher in thailand|           0|        0.0|[0.87563744941621...|\n",
      "|         qlashamusic|           0|        0.0|[0.78186603235272...|\n",
      "|gourmet banana pu...|           0|        0.0|[0.99986967876772...|\n",
      "|ghost -- a music ...|           1|        0.0|[0.70818885942979...|\n",
      "|lf designs embroi...|           0|        0.0|[0.89549633132724...|\n",
      "|\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...|           0|        0.0|[0.78909388747036...|\n",
      "|hero brigade: her...|           1|        1.0|[0.03190588516475...|\n",
      "|custom mosaic wor...|           0|        0.0|[0.78306031594327...|\n",
      "|world's largest b...|           0|        0.0|[0.93506199941097...|\n",
      "|when the editing ...|           0|        0.0|[0.77672690530542...|\n",
      "|gravity single: b...|           1|        1.0|[0.69852697712859...|\n",
      "|dynepod: bringing...|           0|        0.0|[0.86740857295169...|\n",
      "|ohio nerf battle ...|           0|        0.0|[0.99719782430605...|\n",
      "|     wikiprogramming|           0|        1.0|[0.59155103972495...|\n",
      "|the sky colony's ...|           0|        1.0|[0.46568928047495...|\n",
      "|\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...|           0|        0.0|[0.91844861022214...|\n",
      "|under surveillanc...|           0|        0.0|[0.89465719498388...|\n",
      "|           the world|           0|        0.0|[0.80529030077155...|\n",
      "|the future mind o...|           0|        0.0|[0.97327410584977...|\n",
      "|      fight the fear|           0|        0.0|[0.76286498944191...|\n",
      "|create your inten...|           0|        0.0|[0.92181844761887...|\n",
      "|          tldr live!|           0|        0.0|[0.70044366432426...|\n",
      "|sam roark record ...|           0|        0.0|[0.87658280858033...|\n",
      "|vela one - the fa...|           1|        1.0|[0.53094407356336...|\n",
      "|diy tiny house un...|           0|        1.0|[0.69785650076343...|\n",
      "| maggie on the couch|           1|        0.0|[0.91057715804575...|\n",
      "|help me reach the...|           1|        0.0|[0.84111009044922...|\n",
      "|we know clothing ...|           0|        0.0|[0.84553657859997...|\n",
      "|  a. marsden artwork|           1|        1.0|[0.68973570575000...|\n",
      "|engineering throu...|           0|        0.0|[0.86733639999538...|\n",
      "|huntington beach ...|           0|        0.0|[0.79106915992381...|\n",
      "|      signant online|           0|        0.0|[0.80247420300350...|\n",
      "|      black the fall|           1|        1.0|[0.55740760690798...|\n",
      "|upcycled by lilly...|           0|        0.0|[0.87918995338733...|\n",
      "|asmod - jesus lik...|           0|        0.0|[0.77230808779509...|\n",
      "|critter monster o...|           0|        0.0|[0.81254640445263...|\n",
      "|new illustrated w...|           1|        1.0|[0.41618784625187...|\n",
      "|the divine comedy...|           0|        0.0|[0.89765856917518...|\n",
      "| west coast cupcakes|           0|        0.0|[0.81846826550620...|\n",
      "|project guatemala...|           0|        0.0|[0.72763145500239...|\n",
      "|living inside a n...|           0|        0.0|[0.87049972612858...|\n",
      "|milan mode (cance...|           0|        0.0|[0.84718055833369...|\n",
      "|gamer logic - ret...|           0|        0.0|[0.81888385338077...|\n",
      "|rogue wizards rpg...|           1|        1.0|[0.50994508797502...|\n",
      "| lights out tactical|           0|        0.0|[0.75073847646043...|\n",
      "|           bethlehem|           0|        1.0|[0.65369848188584...|\n",
      "|     bespokez launch|           0|        0.0|[0.85303365002884...|\n",
      "|  stories and essays|           0|        1.0|[0.41248363265491...|\n",
      "|the perfect petit...|           0|        1.0|[0.55754039519766...|\n",
      "|v p holmes art & ...|           0|        0.0|[0.70127755077222...|\n",
      "|sonic journey thr...|           1|        0.0|[0.72371982072373...|\n",
      "|enabling you to p...|           0|        0.0|[0.92190080368384...|\n",
      "| www.menswearmag.com|           0|        0.0|[0.91820494689150...|\n",
      "|       arts for kids|           0|        0.0|[0.90625042752955...|\n",
      "|illuminating the ...|           1|        1.0|[0.22560210050982...|\n",
      "|fruitarianism foo...|           0|        0.0|[0.97246172249355...|\n",
      "|    house monkey app|           0|        0.0|[0.83652926998831...|\n",
      "|     sosiick fashion|           0|        0.0|[0.80993327200439...|\n",
      "|what you will (ca...|           0|        0.0|[0.77190347781595...|\n",
      "|\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...|           1|        0.0|[0.86041292366326...|\n",
      "|adventures while ...|           0|        0.0|[0.91007931901238...|\n",
      "|a shining hour st...|           0|        0.0|[0.80898156635932...|\n",
      "|collection of one...|           1|        1.0|[0.62259608588271...|\n",
      "|creative city pro...|           0|        1.0|[0.64120656327729...|\n",
      "|  the wisdom machine|           0|        1.0|[0.67335811708305...|\n",
      "|new tv concept, s...|           0|        0.0|[0.93945651888450...|\n",
      "|chicken bacon pot...|           0|        0.0|[0.83982984473993...|\n",
      "|         13:12 movie|           0|        0.0|[0.84109902307600...|\n",
      "|event cycle 6 - a...|           0|        1.0|[0.55502891006184...|\n",
      "|      dolla 4 impala|           0|        1.0|[0.69311289897640...|\n",
      "| smile lines project|           0|        0.0|[0.86975874740570...|\n",
      "|put a christmas t...|           0|        1.0|[0.58064893882573...|\n",
      "|  free supercomputer|           0|        0.0|[0.80086382927121...|\n",
      "|katstruck models ...|           0|        0.0|[0.94665773543937...|\n",
      "|the sevilla trini...|           0|        1.0|[0.68672152475647...|\n",
      "|selfie - reality ...|           0|        0.0|[0.94608867820963...|\n",
      "|britannia backyar...|           1|        0.0|[0.90693940487446...|\n",
      "|help me get my li...|           0|        0.0|[0.86529233514400...|\n",
      "|cliques - secure ...|           0|        0.0|[0.99143050889607...|\n",
      "|   blissful delights|           0|        0.0|[0.90477816420301...|\n",
      "|mamacitas cafe ::...|           1|        1.0|[0.46502619378163...|\n",
      "|\"lootswaay clothi...|           0|        0.0|[0.77451869467234...|\n",
      "|your prince is in...|           0|        0.0|[0.76347751958759...|\n",
      "|luv it music cana...|           0|        0.0|[0.95553282879772...|\n",
      "|     reunion weekend|           0|        0.0|[0.99030471790818...|\n",
      "|not alice, not wo...|           0|        1.0|[0.61559614725890...|\n",
      "|the line cutterz ...|           1|        1.0|[0.47193548144362...|\n",
      "|\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...|           1|        1.0|[0.43359804296293...|\n",
      "|    martin and marco|           1|        0.0|[0.87903698246486...|\n",
      "|orbiter- playing ...|           0|        0.0|[0.98790232715152...|\n",
      "|gorilla theater p...|           0|        0.0|[0.84728043460593...|\n",
      "|sickos: the very ...|           0|        0.0|[0.83492656343575...|\n",
      "|remote controlled...|           0|        0.0|[0.71941995948101...|\n",
      "+--------------------+------------+-----------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// model.bestModel.params.\n",
    "model.bestModel.transform(test).select(\"name\",\"final_status\",\"predictions\",\"probability\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: Double = 0.6504788520086969\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(model.bestModel.transform(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
